{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddece7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ec2-54-86-71-188.compute-1.amazonaws.com:5000/\n",
      "üèÉ View run luminous-panda-124 at: http://ec2-54-86-71-188.compute-1.amazonaws.com:5000/#/experiments/0/runs/819ead57d4074dc7929399701e1c0f86\n",
      "üß™ View experiment at: http://ec2-54-86-71-188.compute-1.amazonaws.com:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "print(os.getenv('AWS-MLFLOW'))\n",
    "# Get the AWS MLflow URI from .env file\n",
    "aws_mlflow_uri = os.getenv('AWS-MLFLOW')\n",
    "\n",
    "mlflow.set_tracking_uri(aws_mlflow_uri)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 15)\n",
    "    mlflow.log_metric(\"metric1\", 0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5832d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/05 18:44:09 INFO mlflow.tracking.fluent: Experiment with name 'Exp 5 - ML Algos with HP Tuning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://ytsentimentarif/217669177445702737', creation_time=1751730248157, experiment_id='217669177445702737', last_update_time=1751730248157, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9310a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "227e265d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36878, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('reddit_preprocessed.csv').dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c52eec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 18:45:17,159] A new study created in memory with name: no-name-9cab4452-3035-40dc-931c-af81e6893e9c\n",
      "[I 2025-07-05 18:45:33,283] Trial 0 finished with value: 0.5031182212581344 and parameters: {'n_estimators': 161, 'learning_rate': 0.0001211926841090911, 'max_depth': 3}. Best is trial 0 with value: 0.5031182212581344.\n",
      "[I 2025-07-05 18:45:51,332] Trial 1 finished with value: 0.6681127982646421 and parameters: {'n_estimators': 119, 'learning_rate': 0.044699541616931134, 'max_depth': 4}. Best is trial 1 with value: 0.6681127982646421.\n",
      "[I 2025-07-05 18:47:22,286] Trial 2 finished with value: 0.6446583514099783 and parameters: {'n_estimators': 155, 'learning_rate': 0.009551172204424089, 'max_depth': 8}. Best is trial 1 with value: 0.6681127982646421.\n",
      "[I 2025-07-05 18:47:35,950] Trial 3 finished with value: 0.7070227765726681 and parameters: {'n_estimators': 107, 'learning_rate': 0.08991495132277834, 'max_depth': 4}. Best is trial 3 with value: 0.7070227765726681.\n",
      "[I 2025-07-05 18:48:03,918] Trial 4 finished with value: 0.7394251626898047 and parameters: {'n_estimators': 238, 'learning_rate': 0.07108014411864091, 'max_depth': 4}. Best is trial 4 with value: 0.7394251626898047.\n",
      "[I 2025-07-05 18:48:15,780] Trial 5 finished with value: 0.5385032537960954 and parameters: {'n_estimators': 55, 'learning_rate': 0.0025468669424114935, 'max_depth': 5}. Best is trial 4 with value: 0.7394251626898047.\n",
      "[I 2025-07-05 18:48:45,895] Trial 6 finished with value: 0.6917028199566161 and parameters: {'n_estimators': 235, 'learning_rate': 0.03243940778667627, 'max_depth': 4}. Best is trial 4 with value: 0.7394251626898047.\n",
      "[I 2025-07-05 18:49:20,409] Trial 7 finished with value: 0.7304772234273319 and parameters: {'n_estimators': 135, 'learning_rate': 0.07531654703077965, 'max_depth': 6}. Best is trial 4 with value: 0.7394251626898047.\n",
      "[I 2025-07-05 18:50:22,019] Trial 8 finished with value: 0.6157809110629068 and parameters: {'n_estimators': 70, 'learning_rate': 0.003174583183078866, 'max_depth': 10}. Best is trial 4 with value: 0.7394251626898047.\n",
      "[I 2025-07-05 18:52:41,504] Trial 9 finished with value: 0.6392353579175705 and parameters: {'n_estimators': 162, 'learning_rate': 0.004979383561580279, 'max_depth': 10}. Best is trial 4 with value: 0.7394251626898047.\n",
      "[I 2025-07-05 18:54:44,751] Trial 10 finished with value: 0.5783622559652929 and parameters: {'n_estimators': 295, 'learning_rate': 0.0005963791316889363, 'max_depth': 7}. Best is trial 4 with value: 0.7394251626898047.\n",
      "[I 2025-07-05 18:55:53,434] Trial 11 finished with value: 0.6843817787418656 and parameters: {'n_estimators': 232, 'learning_rate': 0.019891753378464917, 'max_depth': 6}. Best is trial 4 with value: 0.7394251626898047.\n",
      "[I 2025-07-05 18:56:38,989] Trial 12 finished with value: 0.7790130151843818 and parameters: {'n_estimators': 210, 'learning_rate': 0.09713554971997171, 'max_depth': 6}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 18:58:48,228] Trial 13 finished with value: 0.6834327548806941 and parameters: {'n_estimators': 234, 'learning_rate': 0.014396747414352453, 'max_depth': 8}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 18:59:21,132] Trial 14 finished with value: 0.7601681127982647 and parameters: {'n_estimators': 201, 'learning_rate': 0.09300135122838163, 'max_depth': 5}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 19:00:39,225] Trial 15 finished with value: 0.5649403470715835 and parameters: {'n_estimators': 185, 'learning_rate': 0.0004739139134439633, 'max_depth': 7}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 19:01:19,007] Trial 16 finished with value: 0.6936008676789588 and parameters: {'n_estimators': 197, 'learning_rate': 0.031310128124363464, 'max_depth': 5}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 19:03:53,677] Trial 17 finished with value: 0.663909978308026 and parameters: {'n_estimators': 273, 'learning_rate': 0.008304161485702611, 'max_depth': 8}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 19:04:37,563] Trial 18 finished with value: 0.5538232104121475 and parameters: {'n_estimators': 206, 'learning_rate': 0.000971733052800818, 'max_depth': 5}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 19:05:39,944] Trial 19 finished with value: 0.6776030368763557 and parameters: {'n_estimators': 209, 'learning_rate': 0.0216432943479668, 'max_depth': 6}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 19:06:01,807] Trial 20 finished with value: 0.7086496746203904 and parameters: {'n_estimators': 264, 'learning_rate': 0.05104682281832699, 'max_depth': 3}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 19:06:42,545] Trial 21 finished with value: 0.767353579175705 and parameters: {'n_estimators': 251, 'learning_rate': 0.08088669254350789, 'max_depth': 5}. Best is trial 12 with value: 0.7790130151843818.\n",
      "[I 2025-07-05 19:07:23,685] Trial 22 finished with value: 0.7811822125813449 and parameters: {'n_estimators': 262, 'learning_rate': 0.09672608899830334, 'max_depth': 5}. Best is trial 22 with value: 0.7811822125813449.\n",
      "[I 2025-07-05 19:08:49,300] Trial 23 finished with value: 0.7472885032537961 and parameters: {'n_estimators': 264, 'learning_rate': 0.04124591751346016, 'max_depth': 7}. Best is trial 22 with value: 0.7811822125813449.\n",
      "[I 2025-07-05 19:10:11,498] Trial 24 finished with value: 0.7085140997830802 and parameters: {'n_estimators': 297, 'learning_rate': 0.022494524935738305, 'max_depth': 6}. Best is trial 22 with value: 0.7811822125813449.\n",
      "[I 2025-07-05 19:10:51,631] Trial 25 finished with value: 0.7810466377440347 and parameters: {'n_estimators': 257, 'learning_rate': 0.09835720335098459, 'max_depth': 5}. Best is trial 22 with value: 0.7811822125813449.\n",
      "[I 2025-07-05 19:13:57,919] Trial 26 finished with value: 0.6898047722342733 and parameters: {'n_estimators': 276, 'learning_rate': 0.012065591859105091, 'max_depth': 9}. Best is trial 22 with value: 0.7811822125813449.\n",
      "[I 2025-07-05 19:14:51,745] Trial 27 finished with value: 0.737527114967462 and parameters: {'n_estimators': 217, 'learning_rate': 0.04968094633520956, 'max_depth': 6}. Best is trial 22 with value: 0.7811822125813449.\n",
      "[I 2025-07-05 19:15:23,181] Trial 28 finished with value: 0.7722342733188721 and parameters: {'n_estimators': 282, 'learning_rate': 0.09856366991615698, 'max_depth': 4}. Best is trial 22 with value: 0.7811822125813449.\n",
      "[I 2025-07-05 19:15:47,211] Trial 29 finished with value: 0.5031182212581344 and parameters: {'n_estimators': 251, 'learning_rate': 0.00011905047565520004, 'max_depth': 3}. Best is trial 22 with value: 0.7811822125813449.\n",
      "2025/07/05 19:16:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/05 19:17:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBoost_SMOTE_TFIDF_Trigrams at: http://ec2-54-86-71-188.compute-1.amazonaws.com:5000/#/experiments/217669177445702737/runs/09e76d23f4044388982d4ef2857f2224\n",
      "üß™ View experiment at: http://ec2-54-86-71-188.compute-1.amazonaws.com:5000/#/experiments/217669177445702737\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
    "data['category'] = data['category'].map({-1: 2, 0: 0, 1: 1})\n",
    "\n",
    "# Step 2: Remove rows where the target labels (category) are NaN\n",
    "data = data.dropna(subset=['category'])\n",
    "\n",
    "ngram_range = (1, 3)  # Trigram setting\n",
    "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "# Step 4: Train-test split before vectorization and resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['clean_comment'], data['category'], test_size=0.2, random_state=42, stratify=data['category'])\n",
    "\n",
    "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Function to log results in MLflow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "\n",
    "# Step 6: Optuna objective function for XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "\n",
    "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
    "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
    "\n",
    "\n",
    "# Step 7: Run Optuna for XGBoost, log the best model only\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_xgboost, n_trials=30)\n",
    "\n",
    "    # Get the best parameters and log only the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
    "\n",
    "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
    "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "\n",
    "# Run the experiment for XGBoost\n",
    "run_optuna_experiment()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
